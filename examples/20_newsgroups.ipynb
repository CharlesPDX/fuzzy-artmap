{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the 20 Newsgroups data set from scikit learn\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroup_data = fetch_20newsgroups(subset=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help the interpreter find the fuzzy_artmap module \n",
    "import os, sys\n",
    "dir2 = os.path.abspath('')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from dataclasses import dataclass\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from fuzzy_artmap import FuzzyArtMap\n",
    "\n",
    "@dataclass\n",
    "class ProcessedCorpus:\n",
    "    vectorized_corpus: csr_matrix\n",
    "    document_corpus_map: dict[int: int]\n",
    "    categories: dict[int: list[str]]\n",
    "\n",
    "\n",
    "def get_tf_idf_twenty_newsgroup_corpus() -> ProcessedCorpus:\n",
    "    \"\"\"Helper function to vectorize the 20 Newsgroup corpus to TF-IDF features, and associate the vectorized documents with their categories\"\"\"\n",
    "    twenty_newsgroup_vectorizer = TfidfVectorizer(input=\"content\", encoding=\"latin1\", stop_words='english', min_df=0.001, max_df=0.9)\n",
    "    twenty_newsgroup_vectorized_corpus = twenty_newsgroup_vectorizer.fit_transform(newsgroup_data.data)\n",
    "    categories = list(newsgroup_data.target_names)\n",
    "    twenty_newsgroup_categories = {}\n",
    "    for document_index, category_index in enumerate(newsgroup_data.target):\n",
    "        twenty_newsgroup_categories[document_index]=categories[category_index]\n",
    "\n",
    "    return ProcessedCorpus(vectorized_corpus = twenty_newsgroup_vectorized_corpus,\n",
    "                           document_corpus_map = {index: index for index in range(twenty_newsgroup_vectorized_corpus.shape[0])},\n",
    "                           categories = twenty_newsgroup_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Setup the valid (matching) & invalid (not matching) categories, complement encoded\n",
    "valid_vector = torch.tensor([[1.0, 0.0]])\n",
    "invalid_vector = torch.tensor([[0.0, 1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_input_and_output(doc_index, vector, categories, relevant_category):\n",
    "    \"\"\"Helper function to get the complement encoded input, and encoded label\"\"\"\n",
    "    if relevant_category == categories[doc_index]:\n",
    "        output_value = valid_vector\n",
    "    else:\n",
    "        output_value = invalid_vector\n",
    "    \n",
    "    complement_encoded_input = FuzzyArtMap.complement_encode(torch.from_numpy(vector.toarray()))\n",
    "    return complement_encoded_input, output_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predictions(fuzzy_artmap, document_indexes, corpus, categories, relevant_category, document_corpus_index_map):\n",
    "    \"\"\"Count the True Positives (TP), True Negatives (TN), False Positives (FP), and False Negatives (FN) for predictions made by the model\"\"\"\n",
    "    accuracy_counter = Counter({\"TP\": 0, \"TN\": 0, \"FP\": 0, \"FN\": 0})\n",
    "    for corpus_index in document_indexes[100:]:  # Skip the first 100 documents used for training\n",
    "        document_index = document_corpus_index_map[corpus_index]\n",
    "        input_vector, class_vector = get_test_input_and_output(document_index, corpus[corpus_index], categories, relevant_category)\n",
    "        prediction = fuzzy_artmap.predict(input_vector)\n",
    "        if class_vector[0][0].item():\n",
    "            if prediction[0][0][0].item():\n",
    "                update = {\"TP\": 1}\n",
    "            else:\n",
    "                update = {\"FN\": 1}\n",
    "        else:\n",
    "            if prediction[0][0][0].item():\n",
    "                update = {\"FP\": 1}\n",
    "            else:\n",
    "                update = {\"TN\": 1}\n",
    "        accuracy_counter.update(update)\n",
    "    print(accuracy_counter)\n",
    "    return accuracy_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(accuracy_data, duration, number_of_relevant_documents):\n",
    "    \"\"\"Calculate accuracy, precision, recall, and speed metrics given the accuracy data\"\"\"\n",
    "    total_documents_tested = sum(accuracy_data.values())\n",
    "    accuracy = (accuracy_data[\"TP\"] + accuracy_data[\"TN\"]) / total_documents_tested\n",
    "    precision = accuracy_data[\"TP\"] / (accuracy_data[\"TP\"] + accuracy_data[\"FP\"])\n",
    "    recall = accuracy_data[\"TP\"] / (accuracy_data[\"TP\"] + accuracy_data[\"FN\"])\n",
    "    recall_set = accuracy_data[\"TP\"] / number_of_relevant_documents\n",
    "    rate = total_documents_tested / duration.seconds\n",
    "    print(f\"accuracy: {accuracy}\\nprecision: {precision}\\nrecall: {recall}\\nrecall (set): {recall_set}\\ntotal relevant docs: {number_of_relevant_documents}\\ntotal docs:{total_documents_tested}\\nprediction rate (docs/second):{rate}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_twenty_newsgroup_corpus():\n",
    "    global relevant_category\n",
    "    relevant_category = \"alt.atheism\" \n",
    "    seed_indexes = [4000, 4001]\n",
    "    processed_corpus = get_tf_idf_twenty_newsgroup_corpus()\n",
    "    categories = {index: category for index, category in processed_corpus.categories.items() if index not in seed_indexes }\n",
    "    categories[4000] = \"alt.atheism\"\n",
    "    categories[4001] = \"alt.atheism\"\n",
    "    shuffled_document_indexes = seed_indexes + random.sample(list(categories.keys()), len(categories))\n",
    "    return processed_corpus.vectorized_corpus, processed_corpus.categories, shuffled_document_indexes, processed_corpus.document_corpus_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_document_indexes = set()\n",
    "\n",
    "def train_model(corpus, shuffled_document_indexes, categories, relevant_category, document_corpus_index_map):\n",
    "    fuzzy_artmap = FuzzyArtMap(number_of_category_nodes=36, baseline_vigilance=0.95)\n",
    "    training_split = Counter()\n",
    "    for iteration_count, corpus_index in enumerate(shuffled_document_indexes[:100]):\n",
    "        document_index = document_corpus_index_map[corpus_index]\n",
    "        # print(f\"{iteration_count} - {categories[document_index]}\")\n",
    "        training_split.update({''.join(categories[document_index]):1})\n",
    "        input_vector, class_vector = get_test_input_and_output(document_index, corpus[corpus_index], categories, relevant_category)\n",
    "        fuzzy_artmap.fit(input_vector, class_vector)\n",
    "    processed_document_indexes.update(shuffled_document_indexes[:100])\n",
    "    return fuzzy_artmap, training_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start predictions: 2024-12-09 14:23:42.510335\n",
      "Counter({'TN': 17951, 'FN': 796, 'TP': 1, 'FP': 0})\n",
      "end predictions: 2024-12-09 14:24:12.170432 - elapsed: 0:00:29.660097\n",
      "accuracy: 0.957542137828035\n",
      "precision: 1.0\n",
      "recall: 0.0012547051442910915\n",
      "recall (set): 0.0012547051442910915\n",
      "total relevant docs: 797\n",
      "total docs:18748\n",
      "prediction rate (docs/second):646.4827586206897\n"
     ]
    }
   ],
   "source": [
    "# This cell trains a basic model using naive (random sample) one-shot offline training using 100 documents, \n",
    "# and then runs the prediction, calculating the performance metrics\n",
    "\n",
    "relevant_category = \"alt.atheism\"\n",
    "\n",
    "corpus, categories, shuffled_document_indexes, document_corpus_index_map = setup_twenty_newsgroup_corpus()\n",
    "fuzzy_artmap, training_split = train_model(corpus, shuffled_document_indexes, categories, relevant_category, document_corpus_index_map)\n",
    "\n",
    "start_predictions = datetime.datetime.now()\n",
    "print(f\"start predictions: {start_predictions}\")\n",
    "accuracy_data = test_predictions(fuzzy_artmap, shuffled_document_indexes, corpus, categories, relevant_category, document_corpus_index_map)\n",
    "\n",
    "end_predictions = datetime.datetime.now()\n",
    "prediction_duration = end_predictions-start_predictions\n",
    "print(f\"end predictions: {end_predictions} - elapsed: {prediction_duration}\")\n",
    "\n",
    "number_of_relevant_documents = len(list([i for i in shuffled_document_indexes[100:] if relevant_category in categories[document_corpus_index_map[i]]]))\n",
    "calculate_metrics(accuracy_data, prediction_duration, number_of_relevant_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(fuzzy_artmap, corpus, categories, available_document_indexes, document_corpus_index_map):\n",
    "    \"\"\"Gets the predictions for the remaining unevaluated documents in the corpus\"\"\"\n",
    "    working_indexes = list(available_document_indexes)\n",
    "\n",
    "    predictions = []\n",
    "    for corpus_index in working_indexes:\n",
    "        document_index = document_corpus_index_map[corpus_index]\n",
    "        input_vector, class_vector = get_test_input_and_output(document_index, corpus[corpus_index], categories, relevant_category)\n",
    "        prediction, membership_degree = fuzzy_artmap.predict_with_membership(input_vector)\n",
    "        if prediction[0][0].item():\n",
    "            predictions.append((membership_degree, corpus_index, class_vector, input_vector))\n",
    "    predictions.sort(key=lambda p: p[0], reverse=True)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_active_learning_test(setup_corpus):\n",
    "    \"\"\"Uses an active learning approach to query the 20 Newsgroups corpus for the specified category. The corpus is ranked, the top 100 (`batch_size`) \n",
    "    documents are evaluated against their ground truth label, and the model is updated after every judgement. The evaluated documents are removed from the\n",
    "    available (unevaluated) documents in the corpus. Batch-level metrics are reported after each iteration. Evaluation stops when no more relevant documents\n",
    "    are predicted in the remaining unevaluated documents.\"\"\"\n",
    "    print(f\"start: {datetime.datetime.now()}\")\n",
    "    corpus, categories, shuffled_document_indexes, document_corpus_index_map = setup_corpus()\n",
    "    available_document_indexes = set(shuffled_document_indexes[100:])\n",
    "    number_of_relevant_documents = len(list([i for i in shuffled_document_indexes[100:] if relevant_category in categories[document_corpus_index_map[i]]]))\n",
    "\n",
    "    print(f\"start training: {datetime.datetime.now()}\")    \n",
    "    fuzzy_artmap, _ = train_model(corpus, shuffled_document_indexes, categories, relevant_category, document_corpus_index_map)\n",
    "    \n",
    "    found_relevant_documents = 0\n",
    "    active_learning_iteration = 0\n",
    "    has_candidates = True\n",
    "    start_predictions = datetime.datetime.now()\n",
    "    print(f\"start active learning: {start_predictions}\")\n",
    "    batch_size = 100\n",
    "    evaluated_document_count = 0\n",
    "    while found_relevant_documents != number_of_relevant_documents and has_candidates:        \n",
    "        relevant_documents_in_batch = 0\n",
    "        candidates = query(fuzzy_artmap, corpus, categories, available_document_indexes, document_corpus_index_map)\n",
    "        candidate_batch_size = 0\n",
    "        for candidate in candidates[:batch_size]:\n",
    "            # print(f\"{datetime.datetime.now()} - training\")\n",
    "            evaluated_document_count += 1\n",
    "            candidate_batch_size +=1\n",
    "            fuzzy_artmap.fit(candidate[3], candidate[2])\n",
    "            available_document_indexes.remove(candidate[1]) \n",
    "            if candidate[2][0,][0]:\n",
    "                found_relevant_documents += 1\n",
    "                relevant_documents_in_batch += 1\n",
    "\n",
    "        if len(candidates) == 0:\n",
    "            has_candidates = False\n",
    "        active_learning_iteration += 1\n",
    "        batch_recall = 0\n",
    "        if has_candidates:\n",
    "            batch_recall = relevant_documents_in_batch/candidate_batch_size\n",
    "        print(f\"{datetime.datetime.now()} - {active_learning_iteration} - {found_relevant_documents}/{number_of_relevant_documents} | batch recall: {batch_recall:.4f} | recall - {(found_relevant_documents/number_of_relevant_documents):.4f} precision - {(found_relevant_documents/evaluated_document_count):.4f} | {len(available_document_indexes)}\")\n",
    "    \n",
    "    end_predictions = datetime.datetime.now()\n",
    "    prediction_duration = end_predictions-start_predictions\n",
    "    print(f\"end active learning: {end_predictions} - elapsed: {prediction_duration}\")\n",
    "    print(f\"number of Fuzzy ARTMAP Categories: {fuzzy_artmap.get_weight_a().shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start: 2024-12-09 14:57:48.334254\n",
      "start training: 2024-12-09 14:57:49.748282\n",
      "start active learning: 2024-12-09 14:57:49.987630\n",
      "2024-12-09 14:58:25.682251 - 1 - 15/793 | batch recall: 0.6000 | recall - 0.0189 precision - 0.6000 | 18723\n",
      "2024-12-09 14:58:58.732468 - 2 - 88/793 | batch recall: 0.7300 | recall - 0.1110 precision - 0.7040 | 18623\n",
      "2024-12-09 14:59:31.253182 - 3 - 173/793 | batch recall: 0.8500 | recall - 0.2182 precision - 0.7689 | 18523\n",
      "2024-12-09 14:59:57.965199 - 4 - 255/793 | batch recall: 0.8200 | recall - 0.3216 precision - 0.7846 | 18423\n",
      "2024-12-09 15:00:20.472799 - 5 - 337/793 | batch recall: 0.8200 | recall - 0.4250 precision - 0.7929 | 18323\n",
      "2024-12-09 15:00:41.930662 - 6 - 424/793 | batch recall: 0.8700 | recall - 0.5347 precision - 0.8076 | 18223\n",
      "2024-12-09 15:01:03.344509 - 7 - 498/793 | batch recall: 0.7400 | recall - 0.6280 precision - 0.7968 | 18123\n",
      "2024-12-09 15:01:23.638760 - 8 - 558/793 | batch recall: 0.6000 | recall - 0.7037 precision - 0.7697 | 18023\n",
      "2024-12-09 15:01:43.189919 - 9 - 617/793 | batch recall: 0.5900 | recall - 0.7781 precision - 0.7479 | 17923\n",
      "2024-12-09 15:02:03.594969 - 10 - 650/793 | batch recall: 0.3300 | recall - 0.8197 precision - 0.7027 | 17823\n",
      "2024-12-09 15:02:24.919969 - 11 - 678/793 | batch recall: 0.2800 | recall - 0.8550 precision - 0.6615 | 17723\n",
      "2024-12-09 15:02:48.419835 - 12 - 698/793 | batch recall: 0.2000 | recall - 0.8802 precision - 0.6204 | 17623\n",
      "2024-12-09 15:03:13.519024 - 13 - 713/793 | batch recall: 0.1500 | recall - 0.8991 precision - 0.5820 | 17523\n",
      "2024-12-09 15:03:37.015027 - 14 - 725/793 | batch recall: 0.1200 | recall - 0.9142 precision - 0.5472 | 17423\n",
      "2024-12-09 15:04:01.055440 - 15 - 735/793 | batch recall: 0.1000 | recall - 0.9269 precision - 0.5158 | 17323\n",
      "2024-12-09 15:04:30.268505 - 16 - 742/793 | batch recall: 0.0700 | recall - 0.9357 precision - 0.4866 | 17223\n",
      "2024-12-09 15:04:58.675643 - 17 - 752/793 | batch recall: 0.1000 | recall - 0.9483 precision - 0.4628 | 17123\n",
      "2024-12-09 15:05:50.599700 - 18 - 759/793 | batch recall: 0.0700 | recall - 0.9571 precision - 0.4400 | 17023\n",
      "2024-12-09 15:06:42.079598 - 19 - 762/793 | batch recall: 0.0300 | recall - 0.9609 precision - 0.4175 | 16923\n",
      "2024-12-09 15:07:33.417417 - 20 - 768/793 | batch recall: 0.0652 | recall - 0.9685 precision - 0.4006 | 16831\n",
      "2024-12-09 15:08:24.254847 - 21 - 768/793 | batch recall: 0.0000 | recall - 0.9685 precision - 0.4002 | 16829\n",
      "2024-12-09 15:09:15.709397 - 22 - 768/793 | batch recall: 0.0000 | recall - 0.9685 precision - 0.4002 | 16829\n",
      "end active learning: 2024-12-09 15:09:15.709501 - elapsed: 0:11:25.721871\n",
      "number of Fuzzy ARTMAP Categories: 86\n"
     ]
    }
   ],
   "source": [
    "# Warning, this can take a while to complete 5-15 minutes\n",
    "run_active_learning_test(setup_twenty_newsgroup_corpus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
